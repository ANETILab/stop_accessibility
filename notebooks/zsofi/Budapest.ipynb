{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import h3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "CITY = \"budapest\"\n",
    "VERSION = \"20250428\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts = gpd.read_file(\n",
    "    \"../../data/osm/budapest/budapest_districts_without_margaret_island.geojson\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT = f\"../../output/{CITY}/{VERSION}\"\n",
    "\n",
    "# Read the GeoJSON file where for each stop id we know the multimodal area (5 min walk + 10 min BKK) + ellipticity of this shape + size of the area\n",
    "# and multipolygons describing the 5 min walk from each such station\n",
    "multimodal = gpd.read_file(\n",
    "    f\"{OUTPUT}/stop_geometries_from_walk.geojson\", engine=\"pyogrio\"\n",
    ")\n",
    "# Read GeoJSON file for 15 minute walking distance\n",
    "walking = gpd.read_file(f\"{OUTPUT}/isochrones.geojson\", engine=\"pyogrio\")\n",
    "# read centrality csv\n",
    "centrality = pd.read_csv(f\"{OUTPUT}/merged.csv\", dtype={\"stop_id\": str})\n",
    "\n",
    "# read in geojson for city boundary\n",
    "bp = gpd.read_file(f\"../../data/osm/{CITY}/boundary.geojson\", engine=\"pyogrio\")\n",
    "# Read the pickle with telekom data for socioecon info\n",
    "szk_nap = pd.read_pickle(\"../../data/telekom/szuperkupa_nap_zscores.pkl\")\n",
    "# income = pd.read_csv(\"/mnt/common-ssd/zadorzsofi/telekom/BKK/data/socioecon/stadat-jov0003-14.8.1.2_income_deciles_total.csv\", header=1, index_col=0, delimiter=\";\", thousands=\" \")\n",
    "# distrcit gross income\n",
    "dist_income = pd.read_csv(f\"../../data/statistics/{CITY}/gross_mean_income_2024.csv\")\n",
    "# gini from housing price\n",
    "gini_house_multi = pd.read_csv(f\"{OUTPUT}/multimodal_stop_gini.csv\")\n",
    "gini_house_walk = pd.read_csv(f\"{OUTPUT}/walk15_stop_gini.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raster_id</th>\n",
       "      <th>traffic</th>\n",
       "      <th>remainers</th>\n",
       "      <th>loc_home</th>\n",
       "      <th>loc_work</th>\n",
       "      <th>loc_freq</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>sex_na</th>\n",
       "      <th>arpu_low</th>\n",
       "      <th>...</th>\n",
       "      <th>log_roam_mean</th>\n",
       "      <th>log_roam_std</th>\n",
       "      <th>log_local_mean</th>\n",
       "      <th>log_local_std</th>\n",
       "      <th>log_traffic_z_score_full</th>\n",
       "      <th>log_roam_z_score_full</th>\n",
       "      <th>log_local_z_score_full</th>\n",
       "      <th>log_traffic_z_score</th>\n",
       "      <th>log_roam_z_score</th>\n",
       "      <th>log_local_z_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>8a1e0378c367fff</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>46.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.428571</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>46.571429</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>68.428571</td>\n",
       "      <td>86.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.737667</td>\n",
       "      <td>0.455096</td>\n",
       "      <td>0.685984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.685984</td>\n",
       "      <td>0.766493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>8a1e037a85b7fff</td>\n",
       "      <td>365.714286</td>\n",
       "      <td>100.428571</td>\n",
       "      <td>23.428571</td>\n",
       "      <td>22.571429</td>\n",
       "      <td>11.428571</td>\n",
       "      <td>99.571429</td>\n",
       "      <td>103.571429</td>\n",
       "      <td>162.571429</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.318035</td>\n",
       "      <td>0.260093</td>\n",
       "      <td>5.690899</td>\n",
       "      <td>0.287360</td>\n",
       "      <td>0.629836</td>\n",
       "      <td>1.815712</td>\n",
       "      <td>0.575585</td>\n",
       "      <td>0.698256</td>\n",
       "      <td>3.227631</td>\n",
       "      <td>0.633760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>8a1e0378dd9ffff</td>\n",
       "      <td>91.285714</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>25.571429</td>\n",
       "      <td>24.428571</td>\n",
       "      <td>41.285714</td>\n",
       "      <td>44.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.312927</td>\n",
       "      <td>0.416590</td>\n",
       "      <td>0.482651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.482651</td>\n",
       "      <td>0.526083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.526083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>8a1e0363298ffff</td>\n",
       "      <td>65.714286</td>\n",
       "      <td>20.428571</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.285714</td>\n",
       "      <td>18.428571</td>\n",
       "      <td>17.428571</td>\n",
       "      <td>37.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.164371</td>\n",
       "      <td>0.219665</td>\n",
       "      <td>0.095352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095352</td>\n",
       "      <td>0.101641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>8a1e036ac98ffff</td>\n",
       "      <td>33.857143</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.314008</td>\n",
       "      <td>0.356854</td>\n",
       "      <td>0.583268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.583268</td>\n",
       "      <td>0.642815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.642815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154640</th>\n",
       "      <td>8a1e036ac50ffff</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.685131</td>\n",
       "      <td>0.294352</td>\n",
       "      <td>-1.115885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.115886</td>\n",
       "      <td>-1.365136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.365137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154684</th>\n",
       "      <td>8a1e036a1c67fff</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775294</td>\n",
       "      <td>0.457237</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154698</th>\n",
       "      <td>8a1e036118e7fff</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.709266</td>\n",
       "      <td>0.461908</td>\n",
       "      <td>1.131989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.131989</td>\n",
       "      <td>6.083641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.083630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154720</th>\n",
       "      <td>8a1e0373322ffff</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.029722</td>\n",
       "      <td>0.413670</td>\n",
       "      <td>1.724191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.724191</td>\n",
       "      <td>7.005363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.005352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154754</th>\n",
       "      <td>8a1e0371b99ffff</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388438</td>\n",
       "      <td>0.055028</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28665 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               raster_id     traffic   remainers   loc_home   loc_work  \\\n",
       "87       8a1e0378c367fff  156.000000   46.428571   0.000000   6.428571   \n",
       "255      8a1e037a85b7fff  365.714286  100.428571  23.428571  22.571429   \n",
       "423      8a1e0378dd9ffff   91.285714   27.000000   0.000000   5.000000   \n",
       "591      8a1e0363298ffff   65.714286   20.428571   2.142857   0.000000   \n",
       "759      8a1e036ac98ffff   33.857143    2.428571   0.000000   0.000000   \n",
       "...                  ...         ...         ...        ...        ...   \n",
       "4154640  8a1e036ac50ffff    1.428571    0.000000   0.000000   0.000000   \n",
       "4154684  8a1e036a1c67fff    3.000000    0.000000   0.000000   0.000000   \n",
       "4154698  8a1e036118e7fff    3.428571    0.000000   0.000000   0.000000   \n",
       "4154720  8a1e0373322ffff    5.714286    0.000000   0.000000   0.000000   \n",
       "4154754  8a1e0371b99ffff    1.428571    0.000000   0.000000   0.000000   \n",
       "\n",
       "          loc_freq  sex_female    sex_male      sex_na    arpu_low  ...  \\\n",
       "87        1.714286   46.571429   41.000000   68.428571   86.857143  ...   \n",
       "255      11.428571   99.571429  103.571429  162.571429  183.000000  ...   \n",
       "423       1.428571   25.571429   24.428571   41.285714   44.857143  ...   \n",
       "591       0.000000   20.285714   18.428571   17.428571   37.714286  ...   \n",
       "759       0.000000    6.000000    7.285714    6.857143    8.000000  ...   \n",
       "...            ...         ...         ...         ...         ...  ...   \n",
       "4154640   0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
       "4154684   0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
       "4154698   0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
       "4154720   0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
       "4154754   0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
       "\n",
       "         log_roam_mean  log_roam_std  log_local_mean  log_local_std  \\\n",
       "87          -11.512925      0.000000        4.737667       0.455096   \n",
       "255           2.318035      0.260093        5.690899       0.287360   \n",
       "423         -11.512925      0.000000        4.312927       0.416590   \n",
       "591         -11.512925      0.000000        4.164371       0.219665   \n",
       "759         -11.512925      0.000000        3.314008       0.356854   \n",
       "...                ...           ...             ...            ...   \n",
       "4154640     -11.512925      0.000000        0.685131       0.294352   \n",
       "4154684     -11.512925      0.000000        0.775294       0.457237   \n",
       "4154698     -11.512925      0.000000        0.709266       0.461908   \n",
       "4154720     -11.512925      0.000000        1.029722       0.413670   \n",
       "4154754     -11.512925      0.000000        0.388438       0.055028   \n",
       "\n",
       "         log_traffic_z_score_full  log_roam_z_score_full  \\\n",
       "87                       0.685984               0.000000   \n",
       "255                      0.629836               1.815712   \n",
       "423                      0.482651               0.000000   \n",
       "591                      0.095352               0.000000   \n",
       "759                      0.583268               0.000000   \n",
       "...                           ...                    ...   \n",
       "4154640                 -1.115885               0.000000   \n",
       "4154684                  0.707107               0.000000   \n",
       "4154698                  1.131989               0.000000   \n",
       "4154720                  1.724191               0.000000   \n",
       "4154754                 -0.577350               0.000000   \n",
       "\n",
       "         log_local_z_score_full  log_traffic_z_score  log_roam_z_score  \\\n",
       "87                     0.685984             0.766493          0.000000   \n",
       "255                    0.575585             0.698256          3.227631   \n",
       "423                    0.482651             0.526083          0.000000   \n",
       "591                    0.095352             0.101641          0.000000   \n",
       "759                    0.583268             0.642815          0.000000   \n",
       "...                         ...                  ...               ...   \n",
       "4154640               -1.115886            -1.365136          0.000000   \n",
       "4154684                0.707107             0.000000          0.000000   \n",
       "4154698                1.131989             6.083641          0.000000   \n",
       "4154720                1.724191             7.005363          0.000000   \n",
       "4154754               -0.577350            -0.707107          0.000000   \n",
       "\n",
       "         log_local_z_score  \n",
       "87                0.766493  \n",
       "255               0.633760  \n",
       "423               0.526083  \n",
       "591               0.101641  \n",
       "759               0.642815  \n",
       "...                    ...  \n",
       "4154640          -1.365137  \n",
       "4154684           0.000000  \n",
       "4154698           6.083630  \n",
       "4154720           7.005352  \n",
       "4154754          -0.707107  \n",
       "\n",
       "[28665 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "szk_nap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gross labour income per capita by income deciles for Hungary\n",
    "income = (\n",
    "    pd.read_csv(\n",
    "        \"../../data/statistics/hungary/stadat-jov0003-14.8.1.2-en.csv\",\n",
    "        delimiter=\";\",\n",
    "        thousands=\" \",\n",
    "        skiprows=1,\n",
    "        skipfooter=26,\n",
    "        engine=\"python\",\n",
    "    )\n",
    "    .drop(0)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "income.set_index(\"Denomination\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "0. Filter walking to 15min walk\n",
    "1. match hexagons & other small shapes to walking15 shapes and multimodal\n",
    "2. Append to socioecon data\n",
    "3. For multimodal, count average income, nr poor households/total households (poor household %) within area\n",
    "4. For walking15 count within area\n",
    "5. Calculate a) low income ratio b) Gini, c) income entropy -- however how? income level at each location? and characterise low/mid/high income for Gini?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter walking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "walking15 = walking[(walking[\"costing\"] == \"walk\") & (walking[\"range\"] == 15)]\n",
    "walking15 = walking15.copy()\n",
    "walking15.drop(columns=[\"costing\", \"range\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Match hex to shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hexagon_ids(geo_df, hex_resolution=10):\n",
    "    \"\"\"\n",
    "    Adds a column of H3 hexagon IDs to a GeoDataFrame based on its geometries.\n",
    "\n",
    "    Parameters:\n",
    "    geo_df (GeoDataFrame): The input GeoDataFrame with geometries.\n",
    "    hex_resolution (int): The H3 resolution level to use.\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame: The GeoDataFrame with a new column 'hexagon_ids' containing the hexagon IDs.\n",
    "    \"\"\"\n",
    "    hexagon_lists = []  # List to store hexagon IDs for each geometry\n",
    "\n",
    "    # Loop through each geometry in the GeoDataFrame\n",
    "    for idx, row in geo_df.iterrows():\n",
    "        # Ensure the geometry is valid\n",
    "        if row.geometry.is_valid:\n",
    "            # Initialize an empty set to collect hex IDs\n",
    "            hex_ids = set()\n",
    "\n",
    "            # Check if the geometry is a MultiPolygon\n",
    "            if row.geometry.geom_type == \"MultiPolygon\":\n",
    "                # Loop through each Polygon in the MultiPolygon\n",
    "                for polygon in row.geometry.geoms:\n",
    "                    geom_dict = polygon.__geo_interface__  # Get GeoJSON representation\n",
    "                    hex_ids.update(\n",
    "                        h3.polyfill(geom_dict, hex_resolution, geo_json_conformant=True)\n",
    "                    )\n",
    "            else:\n",
    "                # Handle Polygon geometries\n",
    "                geom_dict = row.geometry.__geo_interface__  # Get GeoJSON representation\n",
    "                hex_ids.update(\n",
    "                    h3.polyfill(geom_dict, hex_resolution, geo_json_conformant=True)\n",
    "                )\n",
    "\n",
    "            # Add the hex IDs to the list\n",
    "            hexagon_lists.append(list(hex_ids))\n",
    "        else:\n",
    "            # Add an empty list for invalid geometries\n",
    "            hexagon_lists.append([])\n",
    "\n",
    "    # Add the hexagon IDs as a new column to the GeoDataFrame\n",
    "    geo_df[\"hexagon_ids\"] = hexagon_lists\n",
    "\n",
    "    # Drop rows where 'hexagon_ids' column is empty or contains NaN\n",
    "    geo_df = geo_df[geo_df[\"hexagon_ids\"].apply(lambda x: bool(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match hexagons to 15min walking areas\n",
    "add_hexagon_ids(walking15, hex_resolution=10)\n",
    "# Explode the hexagon_ids column in the walking GeoDataFrame\n",
    "walking15_exploded = walking15.explode(\"hexagon_ids\").rename(\n",
    "    columns={\"hexagon_ids\": \"h3_id\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match hexagons to Multimodal areas\n",
    "add_hexagon_ids(multimodal, hex_resolution=10)\n",
    "# Explode the hexagon_ids column in the walking GeoDataFrame\n",
    "multimodal_exploded = multimodal.explode(\"hexagon_ids\").rename(\n",
    "    columns={\"hexagon_ids\": \"h3_id\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # 2. Append to socioecon data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Assign district level gross mean income to each hex in the district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes based on the district number\n",
    "districts3 = pd.merge(\n",
    "    districts,\n",
    "    dist_income[[\"district\", \"gross_mean_income_2024\"]],\n",
    "    left_on=\"district_number\",\n",
    "    right_on=\"district\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "\n",
    "def h3_to_polygon(h3_id):\n",
    "    \"\"\"Convert a H3 hexagon ID to a Shapely Polygon.\"\"\"\n",
    "    # Get the vertices of the hexagon using h3 library\n",
    "    boundary = h3.h3_to_geo_boundary(h3_id, geo_json=True)\n",
    "    # Convert the list of boundary points into a Polygon\n",
    "    return Polygon(boundary)\n",
    "\n",
    "\n",
    "# Apply the conversion for each raster_id in szk_nap\n",
    "szk_nap[\"geometry\"] = szk_nap[\"raster_id\"].apply(h3_to_polygon)\n",
    "\n",
    "# Now create a GeoDataFrame\n",
    "szk_nap_gdf = gpd.GeoDataFrame(szk_nap, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "# Perform a spatial join to map hexagons to districts\n",
    "szk_nap_gdf2 = gpd.sjoin(szk_nap_gdf, districts3, how=\"left\")\n",
    "\n",
    "szk_nap_gdf3 = szk_nap_gdf2.drop(\n",
    "    columns=[\"geometry\", \"index_right\", \"name\", \"short_name\", \"district_number\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raster_id</th>\n",
       "      <th>traffic</th>\n",
       "      <th>remainers</th>\n",
       "      <th>loc_home</th>\n",
       "      <th>loc_work</th>\n",
       "      <th>loc_freq</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>sex_na</th>\n",
       "      <th>arpu_low</th>\n",
       "      <th>...</th>\n",
       "      <th>log_local_std</th>\n",
       "      <th>log_traffic_z_score_full</th>\n",
       "      <th>log_roam_z_score_full</th>\n",
       "      <th>log_local_z_score_full</th>\n",
       "      <th>log_traffic_z_score</th>\n",
       "      <th>log_roam_z_score</th>\n",
       "      <th>log_local_z_score</th>\n",
       "      <th>osm_id</th>\n",
       "      <th>district</th>\n",
       "      <th>gross_mean_income_2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>8a1e0378c367fff</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>46.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.428571</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>46.571429</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>68.428571</td>\n",
       "      <td>86.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455096</td>\n",
       "      <td>0.685984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.685984</td>\n",
       "      <td>0.766493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766493</td>\n",
       "      <td>1606100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>771000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>8a1e037a85b7fff</td>\n",
       "      <td>365.714286</td>\n",
       "      <td>100.428571</td>\n",
       "      <td>23.428571</td>\n",
       "      <td>22.571429</td>\n",
       "      <td>11.428571</td>\n",
       "      <td>99.571429</td>\n",
       "      <td>103.571429</td>\n",
       "      <td>162.571429</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287360</td>\n",
       "      <td>0.629836</td>\n",
       "      <td>1.815712</td>\n",
       "      <td>0.575585</td>\n",
       "      <td>0.698256</td>\n",
       "      <td>3.227631</td>\n",
       "      <td>0.633760</td>\n",
       "      <td>1606101.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>847000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>8a1e0378dd9ffff</td>\n",
       "      <td>91.285714</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>25.571429</td>\n",
       "      <td>24.428571</td>\n",
       "      <td>41.285714</td>\n",
       "      <td>44.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416590</td>\n",
       "      <td>0.482651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.482651</td>\n",
       "      <td>0.526083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.526083</td>\n",
       "      <td>1606100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>771000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>8a1e0363298ffff</td>\n",
       "      <td>65.714286</td>\n",
       "      <td>20.428571</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.285714</td>\n",
       "      <td>18.428571</td>\n",
       "      <td>17.428571</td>\n",
       "      <td>37.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219665</td>\n",
       "      <td>0.095352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095352</td>\n",
       "      <td>0.101641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101641</td>\n",
       "      <td>1552463.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>698000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>8a1e036ac98ffff</td>\n",
       "      <td>33.857143</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>6.857143</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356854</td>\n",
       "      <td>0.583268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.583268</td>\n",
       "      <td>0.642815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.642815</td>\n",
       "      <td>1550597.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>688000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           raster_id     traffic   remainers   loc_home   loc_work   loc_freq  \\\n",
       "87   8a1e0378c367fff  156.000000   46.428571   0.000000   6.428571   1.714286   \n",
       "255  8a1e037a85b7fff  365.714286  100.428571  23.428571  22.571429  11.428571   \n",
       "423  8a1e0378dd9ffff   91.285714   27.000000   0.000000   5.000000   1.428571   \n",
       "591  8a1e0363298ffff   65.714286   20.428571   2.142857   0.000000   0.000000   \n",
       "759  8a1e036ac98ffff   33.857143    2.428571   0.000000   0.000000   0.000000   \n",
       "\n",
       "     sex_female    sex_male      sex_na    arpu_low  ...  log_local_std  \\\n",
       "87    46.571429   41.000000   68.428571   86.857143  ...       0.455096   \n",
       "255   99.571429  103.571429  162.571429  183.000000  ...       0.287360   \n",
       "423   25.571429   24.428571   41.285714   44.857143  ...       0.416590   \n",
       "591   20.285714   18.428571   17.428571   37.714286  ...       0.219665   \n",
       "759    6.000000    7.285714    6.857143    8.000000  ...       0.356854   \n",
       "\n",
       "     log_traffic_z_score_full  log_roam_z_score_full  log_local_z_score_full  \\\n",
       "87                   0.685984               0.000000                0.685984   \n",
       "255                  0.629836               1.815712                0.575585   \n",
       "423                  0.482651               0.000000                0.482651   \n",
       "591                  0.095352               0.000000                0.095352   \n",
       "759                  0.583268               0.000000                0.583268   \n",
       "\n",
       "     log_traffic_z_score  log_roam_z_score  log_local_z_score     osm_id  \\\n",
       "87              0.766493          0.000000           0.766493  1606100.0   \n",
       "255             0.698256          3.227631           0.633760  1606101.0   \n",
       "423             0.526083          0.000000           0.526083  1606100.0   \n",
       "591             0.101641          0.000000           0.101641  1552463.0   \n",
       "759             0.642815          0.000000           0.642815  1550597.0   \n",
       "\n",
       "     district  gross_mean_income_2024  \n",
       "87        8.0                771000.0  \n",
       "255       6.0                847000.0  \n",
       "423       8.0                771000.0  \n",
       "591      10.0                698000.0  \n",
       "759      23.0                688000.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "szk_nap_gdf3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 15 min walk with df_szk on the H3 hexagon IDs\n",
    "stop_walk15 = pd.merge(\n",
    "    walking15_exploded, szk_nap_gdf3, left_on=\"h3_id\", right_on=\"raster_id\", how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with df_szk on the H3 hexagon IDs\n",
    "stop_multimodal = pd.merge(\n",
    "    multimodal_exploded, szk_nap_gdf2, left_on=\"h3_id\", right_on=\"raster_id\", how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. and 4. Get socioecon information for each multimodal and walking area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to sum and the column to average\n",
    "columns_to_sum = [\n",
    "    \"traffic\",\n",
    "    \"sex_female\",\n",
    "    \"sex_male\",\n",
    "    \"sex_na\",\n",
    "    \"arpu_low\",\n",
    "    \"arpu_mid\",\n",
    "    \"arpu_high\",\n",
    "    \"arpu_na\",\n",
    "    \"age_young\",\n",
    "    \"age_mid\",\n",
    "    \"age_old\",\n",
    "]\n",
    "\n",
    "column_to_avg = \"gross_mean_income_2024\"\n",
    "\n",
    "# For 15-min walking area\n",
    "nr_ppl_per_stop_walk15 = (\n",
    "    stop_walk15.groupby(\"stop_id\")\n",
    "    .agg(\n",
    "        {\n",
    "            **{col: \"sum\" for col in columns_to_sum},  # Sum columns\n",
    "            column_to_avg: \"mean\",  # Average for income - so it takes into account if area is in several districts\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# For multimodal area\n",
    "nr_ppl_per_stop_multimodal = (\n",
    "    stop_multimodal.groupby(\"stop_id\")\n",
    "    .agg(\n",
    "        {\n",
    "            **{col: \"sum\" for col in columns_to_sum},  # Sum  columns\n",
    "            column_to_avg: \"mean\",  # Average for 'Gross mean income monthly 2024'\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate socio-econ changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Income entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nr_ppl_per_stop_multimodal2 = nr_ppl_per_stop_multimodal.set_index(\"stop_id\")\n",
    "# multimodal_rev = nr_ppl_per_stop_multimodal2.drop(\n",
    "#     columns=[\n",
    "#         \"traffic\",\n",
    "#         \"sex_female\",\n",
    "#         \"sex_male\",\n",
    "#         \"sex_na\",\n",
    "#         \"age_young\",\n",
    "#         \"age_mid\",\n",
    "#         \"age_old\",\n",
    "#         \"arpu_high\",\n",
    "#         \"gross_mean_income_2024\",\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multimodal_rev[\"entropy\"] = multimodal_rev.apply(\n",
    "#     lambda row: entropy(row.values, 3), axis=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nr_ppl_per_stop_multimodal = nr_ppl_per_stop_multimodal.merge(\n",
    "#     multimodal_rev[[\"entropy\"]],\n",
    "#     left_on=\"stop_id\",\n",
    "#     right_on=multimodal_rev.index,\n",
    "#     how=\"left\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nr_ppl_per_stop_walk15_2 = nr_ppl_per_stop_walk15.set_index(\"stop_id\")\n",
    "# walk15_rev = nr_ppl_per_stop_walk15_2.drop(\n",
    "#     columns=[\n",
    "#         \"traffic\",\n",
    "#         \"sex_female\",\n",
    "#         \"sex_male\",\n",
    "#         \"sex_na\",\n",
    "#         \"age_young\",\n",
    "#         \"age_mid\",\n",
    "#         \"age_old\",\n",
    "#         \"arpu_high\",\n",
    "#         \"gross_mean_income_2024\",\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk15_rev[\"entropy\"] = walk15_rev.apply(lambda row: entropy(row.values, 3), axis=1)\n",
    "# nr_ppl_per_stop_walk15 = nr_ppl_per_stop_walk15.merge(\n",
    "#     walk15_rev[[\"entropy\"]], left_on=\"stop_id\", right_on=walk15_rev.index, how=\"left\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Revenue index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate Weighted average for multimodal areas\n",
    "\n",
    "# # Calculate the total number of people at each stop\n",
    "# nr_ppl_per_stop_multimodal[\"total\"] = (\n",
    "#     nr_ppl_per_stop_multimodal[\"arpu_low\"]\n",
    "#     + nr_ppl_per_stop_multimodal[\"arpu_mid\"]\n",
    "#     + nr_ppl_per_stop_multimodal[\"arpu_high\"]\n",
    "# )\n",
    "\n",
    "# # Calculate the proportion of each category\n",
    "# nr_ppl_per_stop_multimodal[\"P_low\"] = (\n",
    "#     nr_ppl_per_stop_multimodal[\"arpu_low\"] / nr_ppl_per_stop_multimodal[\"total\"]\n",
    "# )\n",
    "# nr_ppl_per_stop_multimodal[\"P_mid\"] = (\n",
    "#     nr_ppl_per_stop_multimodal[\"arpu_mid\"] / nr_ppl_per_stop_multimodal[\"total\"]\n",
    "# )\n",
    "# nr_ppl_per_stop_multimodal[\"P_high\"] = (\n",
    "#     nr_ppl_per_stop_multimodal[\"arpu_high\"] / nr_ppl_per_stop_multimodal[\"total\"]\n",
    "# )\n",
    "\n",
    "# # Calculate the revenue index using weights -1, 0, and 1\n",
    "# nr_ppl_per_stop_multimodal[\"revenue_index\"] = (\n",
    "#     (-1 * nr_ppl_per_stop_multimodal[\"P_low\"])\n",
    "#     + (0 * nr_ppl_per_stop_multimodal[\"P_mid\"])\n",
    "#     + (1 * nr_ppl_per_stop_multimodal[\"P_high\"])\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate Weighted average for multimodal areas\n",
    "\n",
    "# # Calculate the total number of people at each stop\n",
    "# nr_ppl_per_stop_walk15[\"total\"] = (\n",
    "#     nr_ppl_per_stop_walk15[\"arpu_low\"]\n",
    "#     + nr_ppl_per_stop_walk15[\"arpu_mid\"]\n",
    "#     + nr_ppl_per_stop_walk15[\"arpu_high\"]\n",
    "# )\n",
    "\n",
    "# # Calculate the proportion of each category\n",
    "# nr_ppl_per_stop_walk15[\"P_low\"] = (\n",
    "#     nr_ppl_per_stop_walk15[\"arpu_low\"] / nr_ppl_per_stop_walk15[\"total\"]\n",
    "# )\n",
    "# nr_ppl_per_stop_walk15[\"P_mid\"] = (\n",
    "#     nr_ppl_per_stop_walk15[\"arpu_mid\"] / nr_ppl_per_stop_walk15[\"total\"]\n",
    "# )\n",
    "# nr_ppl_per_stop_walk15[\"P_high\"] = (\n",
    "#     nr_ppl_per_stop_walk15[\"arpu_high\"] / nr_ppl_per_stop_walk15[\"total\"]\n",
    "# )\n",
    "\n",
    "# # Calculate the revenue index using weights -1, 0, and 1\n",
    "# nr_ppl_per_stop_walk15[\"revenue_index\"] = (\n",
    "#     (-1 * nr_ppl_per_stop_walk15[\"P_low\"])\n",
    "#     + (0 * nr_ppl_per_stop_walk15[\"P_mid\"])\n",
    "#     + (1 * nr_ppl_per_stop_walk15[\"P_high\"])\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Gini coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Calculate % difference from Hungary income deciles to low-income, medium income and high income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Helsinki I used these deciles, so I'll continue using them for consistency\n",
    "\n",
    "# In the postal code data low-income is nr of people in decile 1 and 2\n",
    "# High-income is nr of people in decile 9-10\n",
    "# So I want to calculate % difference in income from median for low and high income groups and use that in the GINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Bp's Income Differences between median (5th decile) and low/high income\n",
    "median_bp = income.loc[income.index == \"5th income decile\", \"2020\"]\n",
    "\n",
    "low_deciles_avg = income.loc[\n",
    "    income.index.isin([\"1st income decile\", \"2nd income decile\"]), \"2020\"\n",
    "].mean()\n",
    "high_deciles_avg = income.loc[\n",
    "    income.index.isin([\"9th income decile\", \"10th income decile\"]), \"2020\"\n",
    "].mean()\n",
    "\n",
    "low_income_diff = (low_deciles_avg - median_bp) / median_bp\n",
    "high_income_diff = (high_deciles_avg - median_bp) / median_bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate Representative Incomes for walking\n",
    "nr_ppl_per_stop_walk15[\"Low_Income_Rep\"] = nr_ppl_per_stop_walk15[\n",
    "    \"gross_mean_income_2024\"\n",
    "] * (1 + float(low_income_diff.iloc[0]))\n",
    "nr_ppl_per_stop_walk15[\"High_Income_Rep\"] = nr_ppl_per_stop_walk15[\n",
    "    \"gross_mean_income_2024\"\n",
    "] * (1 + float(high_income_diff.iloc[0]))\n",
    "\n",
    "# Estimate Representative Incomes for multimodal\n",
    "nr_ppl_per_stop_multimodal[\"Low_Income_Rep\"] = nr_ppl_per_stop_multimodal[\n",
    "    \"gross_mean_income_2024\"\n",
    "] * (1 + float(low_income_diff.iloc[0]))\n",
    "nr_ppl_per_stop_multimodal[\"High_Income_Rep\"] = nr_ppl_per_stop_multimodal[\n",
    "    \"gross_mean_income_2024\"\n",
    "] * (1 + float(high_income_diff.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Apply % difference to walking and multimodal areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an array (column), where each income category is repeated the houshold nr times\n",
    "# this will be used for gini calculation\n",
    "def create_income_distribution(row):\n",
    "    low_income = [row[\"Low_Income_Rep\"]] * int(row[\"arpu_low\"])\n",
    "    middle_income = [row[\"gross_mean_income_2024\"]] * int(row[\"arpu_mid\"])\n",
    "    high_income = [row[\"High_Income_Rep\"]] * int(row[\"arpu_high\"])\n",
    "    return low_income + middle_income + high_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define gini\n",
    "def gini(array):\n",
    "    \"\"\"Calculate the Gini coefficient of a numpy array.\n",
    "    Based on code from: https://github.com/oliviaguest/gini\"\"\"\n",
    "    array = np.array(\n",
    "        array, dtype=float\n",
    "    )  # change from Olivia: Convert to NumPy array and flatten\n",
    "    if (\n",
    "        array.size == 0 or np.sum(array) == 0\n",
    "    ):  # change from Olivia, as I have empty arrays\n",
    "        return np.nan  # handle 0 divisions\n",
    "    array = np.sort(array)\n",
    "    n = array.size\n",
    "    index = np.arange(1, n + 1)\n",
    "    return (np.sum((2 * index - n - 1) * array)) / (n * np.sum(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_ppl_per_stop_walk15[\"Income_Distribution\"] = nr_ppl_per_stop_walk15.apply(\n",
    "    create_income_distribution, axis=1\n",
    ")\n",
    "nr_ppl_per_stop_walk15[\"gini\"] = nr_ppl_per_stop_walk15[\"Income_Distribution\"].apply(\n",
    "    gini\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_ppl_per_stop_multimodal[\"Income_Distribution\"] = nr_ppl_per_stop_multimodal.apply(\n",
    "    create_income_distribution, axis=1\n",
    ")\n",
    "nr_ppl_per_stop_multimodal[\"gini\"] = nr_ppl_per_stop_multimodal[\n",
    "    \"Income_Distribution\"\n",
    "].apply(gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Merge Gini from housing prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column in gini_house_multi\n",
    "gini_house_multi = gini_house_multi.rename(columns={\"multimodal_gini\": \"gini_house\"})\n",
    "\n",
    "# Rename column in gini_house_walk\n",
    "gini_house_walk = gini_house_walk.rename(columns={\"walk15_gini\": \"gini_house\"})\n",
    "\n",
    "# Merge for multimodal\n",
    "nr_ppl_per_stop_multimodal = pd.merge(\n",
    "    gini_house_multi,\n",
    "    nr_ppl_per_stop_multimodal,\n",
    "    on=\"stop_id\",\n",
    "    how=\"left\",  # or 'inner' depending on your goal\n",
    ")\n",
    "\n",
    "# Merge for walk\n",
    "nr_ppl_per_stop_walk15 = pd.merge(\n",
    "    gini_house_walk, nr_ppl_per_stop_walk15, on=\"stop_id\", how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate socioecon ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_ppl_per_stop_walk15[\"fem_ratio\"] = (\n",
    "    nr_ppl_per_stop_walk15[\"sex_female\"] / nr_ppl_per_stop_walk15[\"traffic\"]\n",
    ")\n",
    "nr_ppl_per_stop_walk15[\"arpu_low_ratio\"] = (\n",
    "    nr_ppl_per_stop_walk15[\"arpu_low\"] / nr_ppl_per_stop_walk15[\"traffic\"]\n",
    ")\n",
    "nr_ppl_per_stop_walk15[\"arpu_high_ratio\"] = (\n",
    "    nr_ppl_per_stop_walk15[\"arpu_high\"] / nr_ppl_per_stop_walk15[\"traffic\"]\n",
    ")\n",
    "nr_ppl_per_stop_walk15[\"young_ratio\"] = (\n",
    "    nr_ppl_per_stop_walk15[\"age_young\"] / nr_ppl_per_stop_walk15[\"traffic\"]\n",
    ")\n",
    "nr_ppl_per_stop_walk15[\"old_ratio\"] = (\n",
    "    nr_ppl_per_stop_walk15[\"age_old\"] / nr_ppl_per_stop_walk15[\"traffic\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_ppl_per_stop_multimodal[\"fem_ratio\"] = (\n",
    "    nr_ppl_per_stop_multimodal[\"sex_female\"] / nr_ppl_per_stop_multimodal[\"traffic\"]\n",
    ")\n",
    "nr_ppl_per_stop_multimodal[\"arpu_low_ratio\"] = (\n",
    "    nr_ppl_per_stop_multimodal[\"arpu_low\"] / nr_ppl_per_stop_multimodal[\"traffic\"]\n",
    ")\n",
    "nr_ppl_per_stop_multimodal[\"arpu_high_ratio\"] = (\n",
    "    nr_ppl_per_stop_multimodal[\"arpu_high\"] / nr_ppl_per_stop_multimodal[\"traffic\"]\n",
    ")\n",
    "nr_ppl_per_stop_multimodal[\"young_ratio\"] = (\n",
    "    nr_ppl_per_stop_multimodal[\"age_young\"] / nr_ppl_per_stop_multimodal[\"traffic\"]\n",
    ")\n",
    "nr_ppl_per_stop_multimodal[\"old_ratio\"] = (\n",
    "    nr_ppl_per_stop_multimodal[\"age_old\"] / nr_ppl_per_stop_multimodal[\"traffic\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames on stop_id with suffixes but remove Income_Dist before merging as I won't need this in the final df\n",
    "nr_ppl_per_stop_comparison = pd.merge(\n",
    "    nr_ppl_per_stop_multimodal.drop(columns=[\"Income_Distribution\"]),\n",
    "    nr_ppl_per_stop_walk15.drop(columns=[\"Income_Distribution\"]),\n",
    "    on=\"stop_id\",\n",
    "    suffixes=(\"_multimodal\", \"_walk15\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate change of some variables\n",
    "nr_ppl_comparison = nr_ppl_per_stop_comparison.dropna()\n",
    "nr_ppl_comparison = nr_ppl_comparison.copy()\n",
    "\n",
    "nr_ppl_comparison.loc[:, \"fem_change\"] = (\n",
    "    nr_ppl_comparison[\"fem_ratio_multimodal\"] - nr_ppl_comparison[\"fem_ratio_walk15\"]\n",
    ")\n",
    "nr_ppl_comparison.loc[:, \"arpu_low_change\"] = (\n",
    "    nr_ppl_comparison[\"arpu_low_ratio_multimodal\"]\n",
    "    - nr_ppl_comparison[\"arpu_low_ratio_walk15\"]\n",
    ")\n",
    "nr_ppl_comparison.loc[:, \"young_change\"] = (\n",
    "    nr_ppl_comparison[\"young_ratio_multimodal\"]\n",
    "    - nr_ppl_comparison[\"young_ratio_walk15\"]\n",
    ")\n",
    "nr_ppl_comparison.loc[:, \"old_change\"] = (\n",
    "    nr_ppl_comparison[\"old_ratio_multimodal\"] - nr_ppl_comparison[\"old_ratio_walk15\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage change\n",
    "nr_ppl_comparison[\"percent_change_gini\"] = np.where(\n",
    "    nr_ppl_comparison[\"gini_walk15\"] == 0,\n",
    "    np.nan,  # because division by 0 is not meaningful, or can be flag value as there is more inequality in the multimodal -- what should be the value?\n",
    "    (nr_ppl_comparison[\"gini_multimodal\"] - nr_ppl_comparison[\"gini_walk15\"])\n",
    "    / nr_ppl_comparison[\"gini_walk15\"]\n",
    "    * 100,\n",
    ")\n",
    "\n",
    "nr_ppl_comparison[\"percent_change_house_gini\"] = np.where(\n",
    "    nr_ppl_comparison[\"gini_house_walk15\"] == 0,\n",
    "    np.nan,  # because division by 0 is not meaningful, or can be flag value as there is more inequality in the multimodal -- what should be the value?\n",
    "    (nr_ppl_comparison[\"gini_house_multimodal\"] - nr_ppl_comparison[\"gini_walk15\"])\n",
    "    / nr_ppl_comparison[\"gini_house_walk15\"]\n",
    "    * 100,\n",
    ")\n",
    "\n",
    "# nr_ppl_comparison[\"percent_change_rev_index\"] = (\n",
    "#     (\n",
    "#         nr_ppl_comparison[\"revenue_index_multimodal\"]\n",
    "#         - nr_ppl_comparison[\"revenue_index_walk15\"]\n",
    "#     )\n",
    "#     / nr_ppl_comparison[\"revenue_index_walk15\"]\n",
    "# ) * 100\n",
    "\n",
    "# nr_ppl_comparison[\"percent_change_entropy\"] = (\n",
    "#     (nr_ppl_comparison[\"entropy_multimodal\"] - nr_ppl_comparison[\"entropy_walk15\"])\n",
    "#     / nr_ppl_comparison[\"entropy_walk15\"]\n",
    "# ) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gergo/.cache/pypoetry/virtualenvs/calculate_accessibility-4Q_DyPin-py3.11/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/gergo/.cache/pypoetry/virtualenvs/calculate_accessibility-4Q_DyPin-py3.11/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Gini log change\n",
    "nr_ppl_comparison[\"log_change_gini\"] = np.where(\n",
    "    (nr_ppl_comparison[\"gini_multimodal\"] > 0) & (nr_ppl_comparison[\"gini_walk15\"] > 0),\n",
    "    np.log(nr_ppl_comparison[\"gini_multimodal\"] / nr_ppl_comparison[\"gini_walk15\"]),\n",
    "    np.nan,\n",
    ")\n",
    "\n",
    "# Gini (households) log change\n",
    "nr_ppl_comparison[\"log_change_house_gini\"] = np.where(\n",
    "    (nr_ppl_comparison[\"gini_house_multimodal\"] > 0)\n",
    "    & (nr_ppl_comparison[\"gini_house_walk15\"] > 0),\n",
    "    np.log(\n",
    "        nr_ppl_comparison[\"gini_house_multimodal\"]\n",
    "        / nr_ppl_comparison[\"gini_house_walk15\"]\n",
    "    ),\n",
    "    np.nan,\n",
    ")\n",
    "\n",
    "# # Revenue index log change\n",
    "# nr_ppl_comparison[\"log_change_rev_index\"] = np.where(\n",
    "#     (nr_ppl_comparison[\"revenue_index_multimodal\"] > 0)\n",
    "#     & (nr_ppl_comparison[\"revenue_index_walk15\"] > 0),\n",
    "#     np.log(\n",
    "#         nr_ppl_comparison[\"revenue_index_multimodal\"]\n",
    "#         / nr_ppl_comparison[\"revenue_index_walk15\"]\n",
    "#     ),\n",
    "#     np.nan,\n",
    "# )\n",
    "\n",
    "# # Entropy log change\n",
    "# nr_ppl_comparison[\"log_change_entropy\"] = np.where(\n",
    "#     (nr_ppl_comparison[\"entropy_multimodal\"] > 0)\n",
    "#     & (nr_ppl_comparison[\"entropy_walk15\"] > 0),\n",
    "#     np.log(\n",
    "#         nr_ppl_comparison[\"entropy_multimodal\"] / nr_ppl_comparison[\"entropy_walk15\"]\n",
    "#     ),\n",
    "#     np.nan,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality.drop_duplicates(subset=[\"stop_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames\n",
    "nr_ppl_comparison2 = pd.merge(nr_ppl_comparison, centrality, on=\"stop_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_ppl_comparison2.to_csv(f\"../../output/{CITY}/bp_socioecon_merged5b.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calculate_accessibility-4Q_DyPin-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
