{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import h3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "CITY = \"budapest\"\n",
    "VERSION = \"20250428\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts = gpd.read_file(\n",
    "    \"../../data/osm/budapest/budapest_districts_without_margaret_island.geojson\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT = f\"../../output/{CITY}/{VERSION}\"\n",
    "\n",
    "# Read the GeoJSON file where for each stop id we know the multimodal area (5 min walk + 10 min BKK) + ellipticity of this shape + size of the area\n",
    "# and multipolygons describing the 5 min walk from each such station\n",
    "multimodal = gpd.read_file(\n",
    "    f\"{OUTPUT}/stop_geometries_from_walk.geojson\", engine=\"pyogrio\"\n",
    ")\n",
    "# Read GeoJSON file for 15 minute walking distance\n",
    "walking = gpd.read_file(f\"{OUTPUT}/isochrones.geojson\", engine=\"pyogrio\")\n",
    "# read centrality csv\n",
    "centrality = pd.read_csv(f\"{OUTPUT}/merged.csv\", dtype={\"stop_id\": str})\n",
    "\n",
    "# read in geojson for city boundary\n",
    "bp = gpd.read_file(f\"../../data/osm/{CITY}/boundary.geojson\", engine=\"pyogrio\")\n",
    "# Read the pickle with telekom data for socioecon info\n",
    "szk_nap = pd.read_pickle(\"../../data/telekom/tkom_sept21.pkl\")\n",
    "# income = pd.read_csv(\"/mnt/common-ssd/zadorzsofi/telekom/BKK/data/socioecon/stadat-jov0003-14.8.1.2_income_deciles_total.csv\", header=1, index_col=0, delimiter=\";\", thousands=\" \")\n",
    "# distrcit gross income\n",
    "dist_income = pd.read_csv(f\"../../data/statistics/{CITY}/gross_mean_income_2024.csv\")\n",
    "# gini from housing price\n",
    "gini_house_multi = pd.read_csv(f\"{OUTPUT}/multimodal_stop_gini.csv\")\n",
    "gini_house_walk = pd.read_csv(f\"{OUTPUT}/walk15_stop_gini.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gross labour income per capita by income deciles for Hungary\n",
    "income = (\n",
    "    pd.read_csv(\n",
    "        \"../../data/statistics/hungary/stadat-jov0003-14.8.1.2-en.csv\",\n",
    "        delimiter=\";\",\n",
    "        thousands=\" \",\n",
    "        skiprows=1,\n",
    "        skipfooter=26,\n",
    "        engine=\"python\",\n",
    "    )\n",
    "    .drop(0)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "income.set_index(\"Denomination\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "0. Filter walking to 15min walk\n",
    "1. match hexagons & other small shapes to walking15 shapes and multimodal\n",
    "2. Append to socioecon data\n",
    "3. For multimodal, count average income, nr poor households/total households (poor household %) within area\n",
    "4. For walking15 count within area\n",
    "5. Calculate a) low income ratio b) Gini, c) income entropy -- however how? income level at each location? and characterise low/mid/high income for Gini?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter walking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "walking15 = walking[(walking[\"costing\"] == \"walk\") & (walking[\"range\"] == 15)]\n",
    "walking15 = walking15.copy()\n",
    "walking15.drop(columns=[\"costing\", \"range\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Match hex to shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hexagon_ids(geo_df, hex_resolution=10):\n",
    "    \"\"\"\n",
    "    Adds a column of H3 hexagon IDs to a GeoDataFrame based on its geometries.\n",
    "\n",
    "    Parameters:\n",
    "    geo_df (GeoDataFrame): The input GeoDataFrame with geometries.\n",
    "    hex_resolution (int): The H3 resolution level to use.\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame: The GeoDataFrame with a new column 'hexagon_ids' containing the hexagon IDs.\n",
    "    \"\"\"\n",
    "    hexagon_lists = []  # List to store hexagon IDs for each geometry\n",
    "\n",
    "    # Loop through each geometry in the GeoDataFrame\n",
    "    for idx, row in geo_df.iterrows():\n",
    "        # Ensure the geometry is valid\n",
    "        if row.geometry.is_valid:\n",
    "            # Initialize an empty set to collect hex IDs\n",
    "            hex_ids = set()\n",
    "\n",
    "            # Check if the geometry is a MultiPolygon\n",
    "            if row.geometry.geom_type == \"MultiPolygon\":\n",
    "                # Loop through each Polygon in the MultiPolygon\n",
    "                for polygon in row.geometry.geoms:\n",
    "                    geom_dict = polygon.__geo_interface__  # Get GeoJSON representation\n",
    "                    hex_ids.update(\n",
    "                        h3.polyfill(geom_dict, hex_resolution, geo_json_conformant=True)\n",
    "                    )\n",
    "            else:\n",
    "                # Handle Polygon geometries\n",
    "                geom_dict = row.geometry.__geo_interface__  # Get GeoJSON representation\n",
    "                hex_ids.update(\n",
    "                    h3.polyfill(geom_dict, hex_resolution, geo_json_conformant=True)\n",
    "                )\n",
    "\n",
    "            # Add the hex IDs to the list\n",
    "            hexagon_lists.append(list(hex_ids))\n",
    "        else:\n",
    "            # Add an empty list for invalid geometries\n",
    "            hexagon_lists.append([])\n",
    "\n",
    "    # Add the hexagon IDs as a new column to the GeoDataFrame\n",
    "    geo_df[\"hexagon_ids\"] = hexagon_lists\n",
    "\n",
    "    # Drop rows where 'hexagon_ids' column is empty or contains NaN\n",
    "    geo_df = geo_df[geo_df[\"hexagon_ids\"].apply(lambda x: bool(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match hexagons to 15min walking areas\n",
    "add_hexagon_ids(walking15, hex_resolution=10)\n",
    "# Explode the hexagon_ids column in the walking GeoDataFrame\n",
    "walking15_exploded = walking15.explode(\"hexagon_ids\").rename(\n",
    "    columns={\"hexagon_ids\": \"h3_id\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match hexagons to Multimodal areas\n",
    "add_hexagon_ids(multimodal, hex_resolution=10)\n",
    "# Explode the hexagon_ids column in the walking GeoDataFrame\n",
    "multimodal_exploded = multimodal.explode(\"hexagon_ids\").rename(\n",
    "    columns={\"hexagon_ids\": \"h3_id\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # 2. Append to socioecon data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Assign district level gross mean income to each hex in the district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes based on the district number\n",
    "districts3 = pd.merge(\n",
    "    districts,\n",
    "    dist_income[[\"district\", \"gross_mean_income_2024\"]],\n",
    "    left_on=\"district_number\",\n",
    "    right_on=\"district\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "\n",
    "def h3_to_polygon(h3_id):\n",
    "    \"\"\"Convert a H3 hexagon ID to a Shapely Polygon.\"\"\"\n",
    "    # Get the vertices of the hexagon using h3 library\n",
    "    boundary = h3.h3_to_geo_boundary(h3_id, geo_json=True)\n",
    "    # Convert the list of boundary points into a Polygon\n",
    "    return Polygon(boundary)\n",
    "\n",
    "\n",
    "# Apply the conversion for each raster_id in szk_nap\n",
    "szk_nap[\"geometry\"] = szk_nap[\"raster_id\"].apply(h3_to_polygon)\n",
    "\n",
    "# Now create a GeoDataFrame\n",
    "szk_nap_gdf = gpd.GeoDataFrame(szk_nap, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "# Perform a spatial join to map hexagons to districts\n",
    "szk_nap_gdf2 = gpd.sjoin(szk_nap_gdf, districts3, how=\"left\")\n",
    "\n",
    "szk_nap_gdf3 = szk_nap_gdf2.drop(\n",
    "    columns=[\"geometry\", \"index_right\", \"name\", \"short_name\", \"district_number\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raster_id</th>\n",
       "      <th>traffic</th>\n",
       "      <th>arpu_low</th>\n",
       "      <th>arpu_mid</th>\n",
       "      <th>arpu_high</th>\n",
       "      <th>osm_id</th>\n",
       "      <th>district</th>\n",
       "      <th>gross_mean_income_2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8a1e037ac61ffff</td>\n",
       "      <td>590.142857</td>\n",
       "      <td>298.571429</td>\n",
       "      <td>228.714286</td>\n",
       "      <td>45.714286</td>\n",
       "      <td>1605916.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>906000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8a1e037a8b0ffff</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>29.142857</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>1605916.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>906000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8a1e037a8b0ffff</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>29.142857</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>1606043.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>865000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8a1e036ad4f7fff</td>\n",
       "      <td>30.857143</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1550598.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>741000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8a1e036a0927fff</td>\n",
       "      <td>21.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1550597.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>688000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         raster_id     traffic    arpu_low    arpu_mid  arpu_high     osm_id  \\\n",
       "0  8a1e037ac61ffff  590.142857  298.571429  228.714286  45.714286  1605916.0   \n",
       "1  8a1e037a8b0ffff  120.000000   59.000000   29.142857   2.428571  1605916.0   \n",
       "1  8a1e037a8b0ffff  120.000000   59.000000   29.142857   2.428571  1606043.0   \n",
       "2  8a1e036ad4f7fff   30.857143    5.571429    4.714286   0.000000  1550598.0   \n",
       "3  8a1e036a0927fff   21.857143    0.000000    5.571429   0.000000  1550597.0   \n",
       "\n",
       "   district  gross_mean_income_2024  \n",
       "0      13.0                906000.0  \n",
       "1      13.0                906000.0  \n",
       "1      14.0                865000.0  \n",
       "2      18.0                741000.0  \n",
       "3      23.0                688000.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "szk_nap_gdf3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 15 min walk with df_szk on the H3 hexagon IDs\n",
    "stop_walk15 = pd.merge(\n",
    "    walking15_exploded, szk_nap_gdf3, left_on=\"h3_id\", right_on=\"raster_id\", how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with df_szk on the H3 hexagon IDs\n",
    "stop_multimodal = pd.merge(\n",
    "    multimodal_exploded, szk_nap_gdf2, left_on=\"h3_id\", right_on=\"raster_id\", how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. and 4. Get socioecon information for each multimodal and walking area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to sum and the column to average\n",
    "columns_to_sum = [\n",
    "    \"traffic\",\n",
    "    \"arpu_low\",\n",
    "    \"arpu_mid\",\n",
    "    \"arpu_high\",\n",
    "]\n",
    "\n",
    "column_to_avg = \"gross_mean_income_2024\"\n",
    "\n",
    "# For 15-min walking area\n",
    "nr_ppl_per_stop_walk15 = (\n",
    "    stop_walk15.groupby(\"stop_id\")\n",
    "    .agg(\n",
    "        {\n",
    "            **{col: \"sum\" for col in columns_to_sum},  # Sum columns\n",
    "            column_to_avg: \"mean\",  # Average for income - so it takes into account if area is in several districts\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# For multimodal area\n",
    "nr_ppl_per_stop_multimodal = (\n",
    "    stop_multimodal.groupby(\"stop_id\")\n",
    "    .agg(\n",
    "        {\n",
    "            **{col: \"sum\" for col in columns_to_sum},  # Sum  columns\n",
    "            column_to_avg: \"mean\",  # Average for 'Gross mean income monthly 2024'\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate socio-econ changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Gini coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Calculate % difference from Hungary income deciles to low-income, medium income and high income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Helsinki I used these deciles, so I'll continue using them for consistency\n",
    "\n",
    "# In the postal code data low-income is nr of people in decile 1 and 2\n",
    "# High-income is nr of people in decile 9-10\n",
    "# So I want to calculate % difference in income from median for low and high income groups and use that in the GINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Bp's Income Differences between median (5th decile) and low/high income\n",
    "median_bp = income.loc[income.index == \"5th income decile\", \"2020\"]\n",
    "\n",
    "low_deciles_avg = income.loc[\n",
    "    income.index.isin([\"1st income decile\", \"2nd income decile\"]), \"2020\"\n",
    "].mean()\n",
    "high_deciles_avg = income.loc[\n",
    "    income.index.isin([\"9th income decile\", \"10th income decile\"]), \"2020\"\n",
    "].mean()\n",
    "\n",
    "low_income_diff = (low_deciles_avg - median_bp) / median_bp\n",
    "high_income_diff = (high_deciles_avg - median_bp) / median_bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate Representative Incomes for walking\n",
    "nr_ppl_per_stop_walk15[\"Low_Income_Rep\"] = nr_ppl_per_stop_walk15[\n",
    "    \"gross_mean_income_2024\"\n",
    "] * (1 + float(low_income_diff.iloc[0]))\n",
    "nr_ppl_per_stop_walk15[\"High_Income_Rep\"] = nr_ppl_per_stop_walk15[\n",
    "    \"gross_mean_income_2024\"\n",
    "] * (1 + float(high_income_diff.iloc[0]))\n",
    "\n",
    "# Estimate Representative Incomes for multimodal\n",
    "nr_ppl_per_stop_multimodal[\"Low_Income_Rep\"] = nr_ppl_per_stop_multimodal[\n",
    "    \"gross_mean_income_2024\"\n",
    "] * (1 + float(low_income_diff.iloc[0]))\n",
    "nr_ppl_per_stop_multimodal[\"High_Income_Rep\"] = nr_ppl_per_stop_multimodal[\n",
    "    \"gross_mean_income_2024\"\n",
    "] * (1 + float(high_income_diff.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Apply % difference to walking and multimodal areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an array (column), where each income category is repeated the houshold nr times\n",
    "# this will be used for gini calculation\n",
    "def create_income_distribution(row):\n",
    "    low_income = [row[\"Low_Income_Rep\"]] * int(row[\"arpu_low\"])\n",
    "    middle_income = [row[\"gross_mean_income_2024\"]] * int(row[\"arpu_mid\"])\n",
    "    high_income = [row[\"High_Income_Rep\"]] * int(row[\"arpu_high\"])\n",
    "    return low_income + middle_income + high_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define gini\n",
    "def gini(array):\n",
    "    \"\"\"Calculate the Gini coefficient of a numpy array.\n",
    "    Based on code from: https://github.com/oliviaguest/gini\"\"\"\n",
    "    array = np.array(\n",
    "        array, dtype=float\n",
    "    )  # change from Olivia: Convert to NumPy array and flatten\n",
    "    if (\n",
    "        array.size == 0 or np.sum(array) == 0\n",
    "    ):  # change from Olivia, as I have empty arrays\n",
    "        return np.nan  # handle 0 divisions\n",
    "    array = np.sort(array)\n",
    "    n = array.size\n",
    "    index = np.arange(1, n + 1)\n",
    "    return (np.sum((2 * index - n - 1) * array)) / (n * np.sum(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_ppl_per_stop_walk15[\"Income_Distribution\"] = nr_ppl_per_stop_walk15.apply(\n",
    "    create_income_distribution, axis=1\n",
    ")\n",
    "nr_ppl_per_stop_walk15[\"gini\"] = nr_ppl_per_stop_walk15[\"Income_Distribution\"].apply(\n",
    "    gini\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_ppl_per_stop_multimodal[\"Income_Distribution\"] = nr_ppl_per_stop_multimodal.apply(\n",
    "    create_income_distribution, axis=1\n",
    ")\n",
    "nr_ppl_per_stop_multimodal[\"gini\"] = nr_ppl_per_stop_multimodal[\n",
    "    \"Income_Distribution\"\n",
    "].apply(gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Merge Gini from housing prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column in gini_house_multi\n",
    "gini_house_multi = gini_house_multi.rename(columns={\"multimodal_gini\": \"gini_house\"})\n",
    "\n",
    "# Rename column in gini_house_walk\n",
    "gini_house_walk = gini_house_walk.rename(columns={\"walk15_gini\": \"gini_house\"})\n",
    "\n",
    "# Merge for multimodal\n",
    "nr_ppl_per_stop_multimodal = pd.merge(\n",
    "    gini_house_multi,\n",
    "    nr_ppl_per_stop_multimodal,\n",
    "    on=\"stop_id\",\n",
    "    how=\"left\",  # or 'inner' depending on your goal\n",
    ")\n",
    "\n",
    "# Merge for walk\n",
    "nr_ppl_per_stop_walk15 = pd.merge(\n",
    "    gini_house_walk, nr_ppl_per_stop_walk15, on=\"stop_id\", how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate socioecon ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nr_ppl_per_stop_walk15[\"fem_ratio\"] = (\n",
    "#     nr_ppl_per_stop_walk15[\"sex_female\"] / nr_ppl_per_stop_walk15[\"traffic\"]\n",
    "# )\n",
    "nr_ppl_per_stop_walk15[\"arpu_low_ratio\"] = (\n",
    "    nr_ppl_per_stop_walk15[\"arpu_low\"] / nr_ppl_per_stop_walk15[\"traffic\"]\n",
    ")\n",
    "nr_ppl_per_stop_walk15[\"arpu_high_ratio\"] = (\n",
    "    nr_ppl_per_stop_walk15[\"arpu_high\"] / nr_ppl_per_stop_walk15[\"traffic\"]\n",
    ")\n",
    "# nr_ppl_per_stop_walk15[\"young_ratio\"] = (\n",
    "#     nr_ppl_per_stop_walk15[\"age_young\"] / nr_ppl_per_stop_walk15[\"traffic\"]\n",
    "# )\n",
    "# nr_ppl_per_stop_walk15[\"old_ratio\"] = (\n",
    "#     nr_ppl_per_stop_walk15[\"age_old\"] / nr_ppl_per_stop_walk15[\"traffic\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nr_ppl_per_stop_multimodal[\"fem_ratio\"] = (\n",
    "#     nr_ppl_per_stop_multimodal[\"sex_female\"] / nr_ppl_per_stop_multimodal[\"traffic\"]\n",
    "# )\n",
    "nr_ppl_per_stop_multimodal[\"arpu_low_ratio\"] = (\n",
    "    nr_ppl_per_stop_multimodal[\"arpu_low\"] / nr_ppl_per_stop_multimodal[\"traffic\"]\n",
    ")\n",
    "nr_ppl_per_stop_multimodal[\"arpu_high_ratio\"] = (\n",
    "    nr_ppl_per_stop_multimodal[\"arpu_high\"] / nr_ppl_per_stop_multimodal[\"traffic\"]\n",
    ")\n",
    "# nr_ppl_per_stop_multimodal[\"young_ratio\"] = (\n",
    "#     nr_ppl_per_stop_multimodal[\"age_young\"] / nr_ppl_per_stop_multimodal[\"traffic\"]\n",
    "# )\n",
    "# nr_ppl_per_stop_multimodal[\"old_ratio\"] = (\n",
    "#     nr_ppl_per_stop_multimodal[\"age_old\"] / nr_ppl_per_stop_multimodal[\"traffic\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames on stop_id with suffixes but remove Income_Dist before merging as I won't need this in the final df\n",
    "nr_ppl_per_stop_comparison = pd.merge(\n",
    "    nr_ppl_per_stop_multimodal.drop(columns=[\"Income_Distribution\"]),\n",
    "    nr_ppl_per_stop_walk15.drop(columns=[\"Income_Distribution\"]),\n",
    "    on=\"stop_id\",\n",
    "    suffixes=(\"_multimodal\", \"_walk15\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate change of some variables\n",
    "nr_ppl_comparison = nr_ppl_per_stop_comparison.dropna()\n",
    "nr_ppl_comparison = nr_ppl_comparison.copy()\n",
    "\n",
    "# nr_ppl_comparison.loc[:, \"fem_change\"] = (\n",
    "#     nr_ppl_comparison[\"fem_ratio_multimodal\"] - nr_ppl_comparison[\"fem_ratio_walk15\"]\n",
    "# )\n",
    "nr_ppl_comparison.loc[:, \"arpu_low_change\"] = (\n",
    "    nr_ppl_comparison[\"arpu_low_ratio_multimodal\"]\n",
    "    - nr_ppl_comparison[\"arpu_low_ratio_walk15\"]\n",
    ")\n",
    "# nr_ppl_comparison.loc[:, \"young_change\"] = (\n",
    "#     nr_ppl_comparison[\"young_ratio_multimodal\"]\n",
    "#     - nr_ppl_comparison[\"young_ratio_walk15\"]\n",
    "# )\n",
    "# nr_ppl_comparison.loc[:, \"old_change\"] = (\n",
    "#     nr_ppl_comparison[\"old_ratio_multimodal\"] - nr_ppl_comparison[\"old_ratio_walk15\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage change\n",
    "nr_ppl_comparison[\"percent_change_gini\"] = np.where(\n",
    "    nr_ppl_comparison[\"gini_walk15\"] == 0,\n",
    "    np.nan,  # because division by 0 is not meaningful, or can be flag value as there is more inequality in the multimodal -- what should be the value?\n",
    "    (nr_ppl_comparison[\"gini_multimodal\"] - nr_ppl_comparison[\"gini_walk15\"])\n",
    "    / nr_ppl_comparison[\"gini_walk15\"]\n",
    "    * 100,\n",
    ")\n",
    "\n",
    "nr_ppl_comparison[\"percent_change_house_gini\"] = np.where(\n",
    "    nr_ppl_comparison[\"gini_house_walk15\"] == 0,\n",
    "    np.nan,  # because division by 0 is not meaningful, or can be flag value as there is more inequality in the multimodal -- what should be the value?\n",
    "    (nr_ppl_comparison[\"gini_house_multimodal\"] - nr_ppl_comparison[\"gini_walk15\"])\n",
    "    / nr_ppl_comparison[\"gini_house_walk15\"]\n",
    "    * 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gergo/.cache/pypoetry/virtualenvs/calculate_accessibility-4Q_DyPin-py3.11/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/gergo/.cache/pypoetry/virtualenvs/calculate_accessibility-4Q_DyPin-py3.11/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Gini log change\n",
    "nr_ppl_comparison[\"log_change_gini\"] = np.where(\n",
    "    (nr_ppl_comparison[\"gini_multimodal\"] > 0) & (nr_ppl_comparison[\"gini_walk15\"] > 0),\n",
    "    np.log(nr_ppl_comparison[\"gini_multimodal\"] / nr_ppl_comparison[\"gini_walk15\"]),\n",
    "    np.nan,\n",
    ")\n",
    "\n",
    "# Gini (households) log change\n",
    "nr_ppl_comparison[\"log_change_house_gini\"] = np.where(\n",
    "    (nr_ppl_comparison[\"gini_house_multimodal\"] > 0)\n",
    "    & (nr_ppl_comparison[\"gini_house_walk15\"] > 0),\n",
    "    np.log(\n",
    "        nr_ppl_comparison[\"gini_house_multimodal\"]\n",
    "        / nr_ppl_comparison[\"gini_house_walk15\"]\n",
    "    ),\n",
    "    np.nan,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality.drop_duplicates(subset=[\"stop_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames\n",
    "nr_ppl_comparison2 = pd.merge(nr_ppl_comparison, centrality, on=\"stop_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_ppl_comparison2.to_csv(f\"../../output/{CITY}/bp_socioecon_merged5c.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_ppl_comparison2[[\"stop_id\", \"gini_walk15\", \"gini_multimodal\"]].to_csv(\n",
    "    f\"../../output/{CITY}/{VERSION}/stop_gini_from_mobility.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>arpu_low_ratio_walk15</th>\n",
       "      <th>arpu_low_ratio_multimodal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007877</td>\n",
       "      <td>0.278032</td>\n",
       "      <td>0.360259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007878</td>\n",
       "      <td>0.274220</td>\n",
       "      <td>0.373276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007879</td>\n",
       "      <td>0.276003</td>\n",
       "      <td>0.344026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>007881</td>\n",
       "      <td>0.379244</td>\n",
       "      <td>0.371556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>007883</td>\n",
       "      <td>0.358126</td>\n",
       "      <td>0.354507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4024</th>\n",
       "      <td>F04573</td>\n",
       "      <td>0.306491</td>\n",
       "      <td>0.317397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4025</th>\n",
       "      <td>F04574</td>\n",
       "      <td>0.257719</td>\n",
       "      <td>0.321150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4026</th>\n",
       "      <td>F04575</td>\n",
       "      <td>0.259534</td>\n",
       "      <td>0.300188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4027</th>\n",
       "      <td>F04576</td>\n",
       "      <td>0.268701</td>\n",
       "      <td>0.298702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>F04577</td>\n",
       "      <td>0.267427</td>\n",
       "      <td>0.307008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4029 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     stop_id  arpu_low_ratio_walk15  arpu_low_ratio_multimodal\n",
       "0     007877               0.278032                   0.360259\n",
       "1     007878               0.274220                   0.373276\n",
       "2     007879               0.276003                   0.344026\n",
       "3     007881               0.379244                   0.371556\n",
       "4     007883               0.358126                   0.354507\n",
       "...      ...                    ...                        ...\n",
       "4024  F04573               0.306491                   0.317397\n",
       "4025  F04574               0.257719                   0.321150\n",
       "4026  F04575               0.259534                   0.300188\n",
       "4027  F04576               0.268701                   0.298702\n",
       "4028  F04577               0.267427                   0.307008\n",
       "\n",
       "[4029 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr_ppl_comparison2[\n",
    "    [\"stop_id\", \"arpu_low_ratio_walk15\", \"arpu_low_ratio_multimodal\"]\n",
    "].to_csv(f\"../../output/{CITY}/{VERSION}/stop_income_from_mobility.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calculate_accessibility-4Q_DyPin-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
